{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 九 使用ONNX进行部署并推理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 ONNX和ONNX Runtime简介"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通常需要将模型转化为ONNX模型(ONNX模型一般用于中间部署阶段)，然后再拿转化后的ONNX模型进而转化为我们使用不同框架部署需要的类型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ONNX：ONNX通过定义一组与环境和平台无关的标准格式，使AI模型可以在不同框架和环境下交互使用，ONNX可以看作深度学习框架和部署端的桥梁，就像编译器的中间语言一样。硬件和软件厂商只需要基于ONNX标准优化模型性能，让所有兼容ONNX标准的框架受益。转化为ONNX格式后，可以很容易的部署在兼容ONNX的运行环境中。[官网](https://onnx.ai/)/[Github](https://github.com/onnx/onnx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ONNX Runtime：是由微软维护的一个跨平台机器学习推理加速器，它直接对接ONNX，可以直接读取.onnx文件并实现推理，不需要再把 .onnx 格式的文件转换成其他格式的文件。PyTorch借助ONNX Runtime也完成了部署的最后一公里，构建了 PyTorch --> ONNX --> ONNX Runtime 部署流水线，我们只需要将模型转换为 .onnx 文件，并在 ONNX Runtime 上运行模型即可。[官网](https://www.onnxruntime.ai/)/[Github](https://github.com/microsoft/onnxruntime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 安装\n",
    "```\n",
    "pip install onnx onnxruntime\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 适配\n",
    "  - [ONNX和ONNX Runtime的适配关系](https://github.com/microsoft/onnxruntime/blob/master/docs/Versioning.md)\n",
    "  - [ONNX Runtime和CUDA之间的适配关系](https://onnxruntime.ai/docs/execution-providers/CUDA-ExecutionProvider.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 模型导出为ONNX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 模型转换为ONNX格式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 `torch.onnx.export()`把模型转换成 ONNX。转换前必须调用 `model.eval()`或者 `model.train(False)`以确保我们的模型处在推理模式下，避免因为 `dropout`或 `batchnorm`等运算符在推理和训练模式下的不同产生错误"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "import torch.onnx \n",
    "# 转换的onnx格式的名称，文件后缀需为.onnx\n",
    "onnx_file_name = \"xxxxxx.onnx\"\n",
    "# 我们需要转换的模型，将torch_model设置为自己的模型\n",
    "model = torch_model\n",
    "# 加载权重，将model.pth转换为自己的模型权重\n",
    "# 如果模型的权重是使用多卡训练出来，我们需要去除权重中多的module. 具体操作可以见5.4节\n",
    "model = model.load_state_dict(torch.load(\"model.pth\"))\n",
    "# 导出模型前，必须调用model.eval()或者model.train(False)\n",
    "model.eval()\n",
    "# dummy_input就是一个输入的实例，仅提供输入shape、type等信息 \n",
    "batch_size = 1 # 随机的取值，当设置dynamic_axes后影响不大\n",
    "dummy_input = torch.randn(batch_size, 1, 224, 224, requires_grad=True) \n",
    "# 这组输入对应的模型输出\n",
    "output = model(dummy_input)\n",
    "# 导出模型\n",
    "torch.onnx.export(model,        # 模型的名称\n",
    "                  dummy_input,   # 一组实例化输入\n",
    "                  onnx_file_name,   # 文件保存路径/名称\n",
    "                  export_params=True,        #  如果指定为True或默认, 参数也会被导出. 如果你要导出一个没训练过的就设为 False.\n",
    "                  opset_version=10,          # ONNX 算子集的版本，当前已更新到15\n",
    "                  do_constant_folding=True,  # 是否执行常量折叠优化\n",
    "                  input_names = ['input'],   # 输入模型的张量的名称\n",
    "                  output_names = ['output'], # 输出模型的张量的名称\n",
    "                  # dynamic_axes将batch_size的维度指定为动态，\n",
    "                  # 后续进行推理的数据可以与导出的dummy_input的batch_size不同\n",
    "                  dynamic_axes={'input' : {0 : 'batch_size'},    \n",
    "                                'output' : {0 : 'batch_size'}})\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 ONNX模型的检验"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过 `onnx.checker.check_model()`检验ONNX模型文件是否可用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "import onnx\n",
    "# 我们可以使用异常处理的方法进行检验\n",
    "try:\n",
    "    # 当我们的模型不可用时，将会报出异常\n",
    "    onnx.checker.check_model(self.onnx_model)\n",
    "except onnx.checker.ValidationError as e:\n",
    "    print(\"The model is invalid: %s\"%e)\n",
    "else:\n",
    "    # 模型可用时，将不会报出异常，并会输出“The model is valid!”\n",
    "    print(\"The model is valid!\")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 ONNX可视化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`Netron`](https://github.com/lutzroeder/netron)实现onnx的可视化，可以看到整体模型的架构，和每一个节点的信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 使用ONNX Runtime进行推理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用ONNX Runtime运行一下转化后的模型，看一下推理后的结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "# 导入onnxruntime\n",
    "import onnxruntime\n",
    "# 需要进行推理的onnx模型文件名称\n",
    "onnx_file_name = \"xxxxxx.onnx\"\n",
    "\n",
    "# onnxruntime.InferenceSession用于获取一个 ONNX Runtime 推理器\n",
    "ort_session = onnxruntime.InferenceSession(onnx_file_name)  \n",
    "\n",
    "# 构建字典的输入数据，字典的key需要与我们构建onnx模型时的input_names相同\n",
    "# 输入的input_img 也需要改变为ndarray格式\n",
    "ort_inputs = {'input': input_img} \n",
    "# 我们更建议使用下面这种方法,因为避免了手动输入key\n",
    "# ort_inputs = {ort_session.get_inputs()[0].name:input_img}\n",
    "\n",
    "# run是进行模型的推理，第一个参数为输出张量名的列表，一般情况可以设置为None\n",
    "# 第二个参数为构建的输入值的字典\n",
    "# 由于返回的结果被列表嵌套，因此我们需要进行[0]的索引\n",
    "ort_output = ort_session.run(None,ort_inputs)[0]\n",
    "# output = {ort_session.get_outputs()[0].name}\n",
    "# ort_output = ort_session.run([output], ort_inputs)[0]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 注意\n",
    "  1. PyTorch模型的输入为tensor，而ONNX的输入为array，因此我们需要对张量进行变换或者直接将数据读取为array格式，我们可以实现下面的方式进行张量到array的转化。\n",
    "\n",
    "  ```python\n",
    "  def to_numpy(tensor):\n",
    "      return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "  ```\n",
    "\n",
    "  2. 输入的array的shape应该和我们导出模型的 `dummy_input`的shape相同，如果图片大小不一样，我们应该先进行resize操作。\n",
    "  3. run的结果是一个列表，我们需要进行索引操作才能获得array格式的结果。\n",
    "  4. 在构建输入的字典时，我们需要注意字典的key应与导出ONNX格式设置的input_name相同，因此我们更建议使用上述的第二种方法构建输入的字典。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 代码实战"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 定义超分辨模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# 导入相关包\n",
    "import io\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torch.onnx\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "# 定义超分辨网络\n",
    "class SuperResolutionNet(nn.Module):\n",
    "    def __init__(self, upscale_factor, inplace=False):\n",
    "        super(SuperResolutionNet, self).__init__()\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=inplace)\n",
    "        self.conv1 = nn.Conv2d(1, 64, (5, 5), (1, 1), (2, 2))\n",
    "        self.conv2 = nn.Conv2d(64, 64, (3, 3), (1, 1), (1, 1))\n",
    "        self.conv3 = nn.Conv2d(64, 32, (3, 3), (1, 1), (1, 1))\n",
    "        self.conv4 = nn.Conv2d(32, upscale_factor ** 2, (3, 3), (1, 1), (1, 1))\n",
    "        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.pixel_shuffle(self.conv4(x))\n",
    "        return x\n",
    "  \n",
    "\t# 模型初始化\n",
    "    def _initialize_weights(self):\n",
    "        init.orthogonal_(self.conv1.weight, init.calculate_gain('relu'))\n",
    "        init.orthogonal_(self.conv2.weight, init.calculate_gain('relu'))\n",
    "        init.orthogonal_(self.conv3.weight, init.calculate_gain('relu'))\n",
    "        init.orthogonal_(self.conv4.weight)\n",
    "\n",
    "# 实例化模型\n",
    "torch_model = SuperResolutionNet(upscale_factor=3)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 模型导出为ONNX格式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "model_url = 'https://s3.amazonaws.com/pytorch/test_data/export/superres_epoch100-44c6958e.pth'\n",
    "batch_size = 1    # just a random number\n",
    "# 加载预训练得到权重\n",
    "map_location = lambda storage, loc: storage\n",
    "if torch.cuda.is_available():\n",
    "    map_location = None\n",
    "torch_model.load_state_dict(model_zoo.load_url(model_url, map_location=map_location))\n",
    "\n",
    "# 将模型设置为推理模式\n",
    "torch_model.eval()\n",
    "# Input to the model\n",
    "x = torch.randn(batch_size, 1, 224, 224, requires_grad=True)\n",
    "torch_out = torch_model(x)\n",
    "\n",
    "# 导出模型\n",
    "torch.onnx.export(torch_model,               # model being run\n",
    "                  x,             # model input (or a tuple for multiple inputs)\n",
    "                  \"super_resolution.onnx\",   # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=10,   # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names = ['input'],   # the model's input names\n",
    "                  output_names = ['output'], # the model's output names\n",
    "                  # variable length axes\n",
    "                  dynamic_axes={'input' : {0 : 'batch_size'},    \n",
    "                                'output' : {0 : 'batch_size'}})\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 检验ONNX模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import onnx\n",
    "# 我们可以使用异常处理的方法进行检验\n",
    "try:\n",
    "    # 当我们的模型不可用时，将会报出异常\n",
    "    onnx.checker.check_model(\"super_resolution.onnx\")\n",
    "except onnx.checker.ValidationError as e:\n",
    "    print(\"The model is invalid: %s\"%e)\n",
    "else:\n",
    "    # 模型可用时，将不会报出异常，并会输出“The model is valid!”\n",
    "    print(\"The model is valid!\")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 使用ONNX Runtime进行推理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import onnxruntime\n",
    "\n",
    "ort_session = onnxruntime.InferenceSession(\"super_resolution.onnx\")\n",
    "\n",
    "# 将张量转化为ndarray格式\n",
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "# 构建输入的字典和计算输出结果\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(x)}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "\n",
    "# 比较使用PyTorch和ONNX Runtime得出的精度\n",
    "np.testing.assert_allclose(to_numpy(torch_out), ort_outs[0], rtol=1e-03, atol=1e-05)\n",
    "\n",
    "print(\"Exported model has been tested with ONNXRuntime, and the result looks good!\")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 进行实际预测并可视化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# 读取图片\n",
    "img = Image.open(\"/cat_224x224.jpg\")\n",
    "# 对图片进行resize操作\n",
    "resize = transforms.Resize([224, 224])\n",
    "img = resize(img)\n",
    "\n",
    "img_ycbcr = img.convert('YCbCr')\n",
    "img_y, img_cb, img_cr = img_ycbcr.split()\n",
    "\n",
    "to_tensor = transforms.ToTensor()\n",
    "img_y = to_tensor(img_y)\n",
    "img_y.unsqueeze_(0)\n",
    "# 构建输入的字典并将value转换位array格式\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(img_y)}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "img_out_y = ort_outs[0]\n",
    "img_out_y = Image.fromarray(np.uint8((img_out_y[0] * 255.0).clip(0, 255)[0]), mode='L')\n",
    "\n",
    "# 保存最后得到的图片\n",
    "final_img = Image.merge(\n",
    "    \"YCbCr\", [\n",
    "        img_out_y,\n",
    "        img_cb.resize(img_out_y.size, Image.BICUBIC),\n",
    "        img_cr.resize(img_out_y.size, Image.BICUBIC),\n",
    "    ]).convert(\"RGB\")\n",
    "\n",
    "final_img.save(\"/cat_superres_with_ort.jpg\")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
