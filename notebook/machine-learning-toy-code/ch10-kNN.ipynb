{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 十 kNN k最近邻"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 kNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k最近邻（K Nearest Neighbors），监督学习算法，用于分类和回归。如果一个样本在特征空间中的K个最相似(即特征空间中最邻近)的样本中的大多数属于某一个类别，则该样本也属于这个类别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- k值的选取\n",
    "\n",
    "    一般选择一个较小的数值，通常采用交叉验证的方法来选择最优的 K 值\n",
    "\n",
    "- 交叉验证方法\n",
    "  - Hold-out：随机从最初的样本中选出部分，形成交叉验证数据，而剩余的就当做训练数据\n",
    "  - K折交叉验证：将数据集分成k份，将其中一份作为测试集，将剩余的作为训练集，重复k次。平均K次的结果或者使用其它结合方式，最终得到一个单一估测\n",
    "  - 留一法：将数据集分成k份，将其中一份作为测试集，将剩余的作为训练集，重复k次。这个步骤一直持续到每个样本都被当做一次验证资料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 分类决策\n",
    "  - 多数表决法：少数服从多数\n",
    "  - 加权表决法：在数据之间有权重的情况下，一般采用加权表决法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 算法步骤：\n",
    "  1. 准备数据：获取带有标签的训练数据集，包括输入特征和对应的类别或数值\n",
    "  2. 计算距离：对于给定的测试样本，计算其与训练数据集中各个样本之间的距离。常用的距离度量方法有欧氏距离和曼哈顿距离等\n",
    "  3. 选择k值：选择一个合适的k值，即要考虑的最近邻样本的数量。这个值可以根据数据集的大小和问题的特点来确定\n",
    "  4. 选取最近邻：从距离计算中选择k个最近邻样本\n",
    "  5. 判定结果：对于分类问题，通过多数表决决定测试样本的类别，即选择k个最近邻中出现最多次数的类别作为预测结果。对于回归问题，可以取k个最近邻的平均值作为预测结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9844444444444445\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#加载数据集\n",
    "digits = load_digits()\n",
    "data = digits.data     # 特征集\n",
    "target = digits.target # 目标集\n",
    "\n",
    "#将数据集拆分为训练集（75%）和测试集（25%）:\n",
    "train_x, test_x, train_y, test_y = train_test_split(\n",
    "    data, target, test_size=0.25, random_state=33)\n",
    "\n",
    "#构造KNN分类器：采用默认参数\n",
    "knn = KNeighborsClassifier() \n",
    "\n",
    "#拟合模型：\n",
    "knn.fit(train_x, train_y) \n",
    "#预测数据：\n",
    "predict_y = knn.predict(test_x) \n",
    "\n",
    "#计算模型准确度\n",
    "score = accuracy_score(test_y, predict_y)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 自定义实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    def __init__(self, x_train, y_train, x_test, y_test, k):\n",
    "        '''\n",
    "        Args:\n",
    "            x_train [Array]: 训练集数据\n",
    "            y_train [Array]: 训练集标签\n",
    "            x_test [Array]: 测试集数据\n",
    "            y_test [Array]: 测试集标签\n",
    "            k [int]: k of kNN\n",
    "        '''\n",
    "        self.x_train, self.y_train = x_train, y_train\n",
    "        self.x_test, self.y_test = x_test, y_test\n",
    "        # 将输入数据转为矩阵形式，方便运算\n",
    "        self.x_train_mat, self.x_test_mat = np.mat(\n",
    "            self.x_train), np.mat(self.x_test)\n",
    "        self.y_train_mat, self.y_test_mat = np.mat(\n",
    "            self.y_test).T, np.mat(self.y_test).T\n",
    "        self.k = k\n",
    "\n",
    "    def _calc_dist(self, x1, x2):\n",
    "        '''计算两个样本点向量之间的距离,使用的是欧氏距离\n",
    "        :param x1:向量1\n",
    "        :param x2:向量2\n",
    "        :return: 向量之间的欧式距离\n",
    "        '''\n",
    "        return np.sqrt(np.sum(np.square(x1 - x2)))\n",
    "\n",
    "    def _get_k_nearest(self,x):\n",
    "        '''\n",
    "        预测样本x的标记。\n",
    "        获取方式通过找到与样本x最近的topK个点，并查看它们的标签。\n",
    "        查找里面占某类标签最多的那类标签\n",
    "        :param trainDataMat:训练集数据集\n",
    "        :param trainLabelMat:训练集标签集\n",
    "        :param x:待预测的样本x\n",
    "        :param topK:选择参考最邻近样本的数目（样本数目的选择关系到正确率，详看3.2.3 K值的选择）\n",
    "        :return:预测的标记\n",
    "        '''\n",
    "        # 初始化距离列表，dist_list[i]表示待预测样本x与训练集中第i个样本的距离\n",
    "        dist_list=[0]* len(self.x_train_mat)\n",
    "\n",
    "        # 遍历训练集中所有的样本点，计算与x的距离\n",
    "        for i in range( len(self.x_train_mat)):\n",
    "            # 获取训练集中当前样本的向量\n",
    "            x0 = self.x_train_mat[i]\n",
    "            # 计算向量x与训练集样本x0的距离\n",
    "            dist_list[i] = self._calc_dist(x0, x)\n",
    "\n",
    "        # 对距离列表排序并返回距离最近的k个训练样本的下标\n",
    "        # ----------------优化点-------------------\n",
    "        # 由于我们只取topK小的元素索引值，所以其实不需要对整个列表进行排序，而argsort是对整个\n",
    "        # 列表进行排序的，存在时间上的浪费。字典有现成的方法可以只排序top大或top小，可以自行查阅\n",
    "        # 对代码进行稍稍修改即可\n",
    "        # 这里没有对其进行优化主要原因是KNN的时间耗费大头在计算向量与向量之间的距离上，由于向量高维\n",
    "        # 所以计算时间需要很长，所以如果要提升时间，在这里优化的意义不大。\n",
    "        k_nearest_index = np.argsort(np.array(dist_list))[:self.k]  # 升序排序\n",
    "        return k_nearest_index\n",
    "\n",
    "\n",
    "    def _predict_y(self,k_nearest_index):\n",
    "        # label_list[1]=3，表示label为1的样本数有3个，由于此处label为0-9，可以初始化长度为10的label_list\n",
    "        label_list=[0] * 10\n",
    "        for index in k_nearest_index:\n",
    "            one_hot_label=self.y_train[index]\n",
    "            number_label=np.argmax(one_hot_label)\n",
    "            label_list[number_label] += 1\n",
    "        # 采用投票法，即样本数最多的label就是预测的label\n",
    "        y_predict=label_list.index(max(label_list))\n",
    "        return y_predict\n",
    "\n",
    "    def test(self,n_test=200):\n",
    "        '''\n",
    "        测试正确率\n",
    "        :param: n_test: 待测试的样本数\n",
    "        :return: 正确率\n",
    "        '''\n",
    "        print('start test')\n",
    "\n",
    "        # 错误值计数\n",
    "        error_count = 0\n",
    "        # 遍历测试集，对每个测试集样本进行测试\n",
    "        # 由于计算向量与向量之间的时间耗费太大，测试集有6000个样本，所以这里人为改成了\n",
    "        # 测试200个样本点，若要全跑，更改n_test即可\n",
    "        for i in range(n_test):\n",
    "            # print('test %d:%d'%(i, len(trainDataArr)))\n",
    "            print('test %d:%d' % (i, n_test))\n",
    "            # 读取测试集当前测试样本的向量\n",
    "            x = self.x_test_mat[i]\n",
    "            # 获取距离最近的训练样本序号\n",
    "            k_nearest_index=self._get_k_nearest(x)\n",
    "            # 预测输出y\n",
    "            y=self._predict_y(k_nearest_index)\n",
    "            # 如果预测label与实际label不符，错误值计数加1\n",
    "            if y != np.argmax(self.y_test[i]):\n",
    "                error_count += 1\n",
    "            print(\"accuracy=\",1 - (error_count /(i+1)))\n",
    "\n",
    "        # 返回正确率\n",
    "        return 1 - (error_count / n_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
